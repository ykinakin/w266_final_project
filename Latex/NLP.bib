@misc{Hao2022,
  doi = {10.48550/ARXIV.2206.14268},
  url = {https://arxiv.org/abs/2206.14268},
  author = {Hao, Shibo and Tan, Bowen and Tang, Kaiwen and Ni, Bin and Zhang, Hengzhe and Xing, Eric P and Hu, Zhiting},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BertNet: Harvesting Knowledge Graphs from Pretrained Language Models},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Raimondo2022,
  doi = {https://doi.org/10.4095/329265},
  author = {Raimondo, S., Chen, T., Zakharov, A., Brin, L., Kur, D., Hui, J., Burgoyne, S.L., Newton, G., and Lawley, C.J.M.},
  title = {Datasets to support geoscience language models},
  publisher = {Geological Survey of Canada},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Min2021,
  doi = {10.48550/ARXIV.2111.01243},
  url = {https://arxiv.org/abs/2111.01243},
  author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heinz, Ilana and Roth, Dan},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}
